{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7491844,"sourceType":"datasetVersion","datasetId":4361993}],"dockerImageVersionId":30635,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# !pip install -U ipywidgets","metadata":{"execution":{"iopub.status.busy":"2024-02-21T10:42:14.663612Z","iopub.execute_input":"2024-02-21T10:42:14.665176Z","iopub.status.idle":"2024-02-21T10:42:14.711741Z","shell.execute_reply.started":"2024-02-21T10:42:14.665119Z","shell.execute_reply":"2024-02-21T10:42:14.709528Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!pip install polars colorama torch ray recbole kmeans_pytorch tqdm","metadata":{"ExecuteTime":{"end_time":"2024-02-04T19:08:48.878543500Z","start_time":"2024-02-04T19:08:38.203748200Z"},"execution":{"iopub.status.busy":"2024-02-22T12:11:57.510444Z","iopub.execute_input":"2024-02-22T12:11:57.511124Z","iopub.status.idle":"2024-02-22T12:12:16.135427Z","shell.execute_reply.started":"2024-02-22T12:11:57.511072Z","shell.execute_reply":"2024-02-22T12:12:16.134009Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: polars in /opt/conda/lib/python3.10/site-packages (0.20.3)\nRequirement already satisfied: colorama in /opt/conda/lib/python3.10/site-packages (0.4.6)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.0.0+cpu)\nRequirement already satisfied: ray in /opt/conda/lib/python3.10/site-packages (2.6.3)\nCollecting recbole\n  Obtaining dependency information for recbole from https://files.pythonhosted.org/packages/1e/d1/81756635abf971deeaa8180dae167e6ee867f9ffe13dc128a51fb9efe710/recbole-1.2.0-py3-none-any.whl.metadata\n  Downloading recbole-1.2.0-py3-none-any.whl.metadata (1.4 kB)\nCollecting kmeans_pytorch\n  Downloading kmeans_pytorch-0.3-py3-none-any.whl (4.4 kB)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (4.66.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.5.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\nRequirement already satisfied: click>=7.0 in /opt/conda/lib/python3.10/site-packages (from ray) (8.1.7)\nRequirement already satisfied: jsonschema in /opt/conda/lib/python3.10/site-packages (from ray) (4.19.0)\nRequirement already satisfied: msgpack<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from ray) (1.0.5)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from ray) (21.3)\nRequirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /opt/conda/lib/python3.10/site-packages (from ray) (3.20.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from ray) (6.0.1)\nRequirement already satisfied: aiosignal in /opt/conda/lib/python3.10/site-packages (from ray) (1.3.1)\nRequirement already satisfied: frozenlist in /opt/conda/lib/python3.10/site-packages (from ray) (1.4.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from ray) (2.31.0)\nRequirement already satisfied: grpcio>=1.42.0 in /opt/conda/lib/python3.10/site-packages (from ray) (1.57.0)\nRequirement already satisfied: numpy>=1.19.3 in /opt/conda/lib/python3.10/site-packages (from ray) (1.24.3)\nRequirement already satisfied: scipy>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from recbole) (1.11.4)\nRequirement already satisfied: pandas>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from recbole) (2.0.3)\nCollecting colorlog==4.7.2 (from recbole)\n  Downloading colorlog-4.7.2-py2.py3-none-any.whl (10 kB)\nCollecting colorama\n  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\nRequirement already satisfied: scikit-learn>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from recbole) (1.2.2)\nRequirement already satisfied: tensorboard>=2.5.0 in /opt/conda/lib/python3.10/site-packages (from recbole) (2.13.0)\nCollecting thop>=0.1.1.post2207130030 (from recbole)\n  Obtaining dependency information for thop>=0.1.1.post2207130030 from https://files.pythonhosted.org/packages/bb/0f/72beeab4ff5221dc47127c80f8834b4bcd0cb36f6ba91c0b1d04a1233403/thop-0.1.1.post2209072238-py3-none-any.whl.metadata\n  Downloading thop-0.1.1.post2209072238-py3-none-any.whl.metadata (2.7 kB)\nRequirement already satisfied: tabulate>=0.8.10 in /opt/conda/lib/python3.10/site-packages (from recbole) (0.9.0)\nRequirement already satisfied: plotly>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from recbole) (5.16.1)\nRequirement already satisfied: texttable>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from recbole) (1.7.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.4.0->recbole) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.4.0->recbole) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.4.0->recbole) (2023.3)\nRequirement already satisfied: tenacity>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from plotly>=4.0.0->recbole) (8.2.3)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.23.2->recbole) (1.3.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.23.2->recbole) (3.2.0)\nRequirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.10/site-packages (from tensorboard>=2.5.0->recbole) (1.4.0)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard>=2.5.0->recbole) (2.22.0)\nRequirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard>=2.5.0->recbole) (1.0.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard>=2.5.0->recbole) (3.4.4)\nRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard>=2.5.0->recbole) (68.1.2)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard>=2.5.0->recbole) (0.7.1)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard>=2.5.0->recbole) (3.0.1)\nRequirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.10/site-packages (from tensorboard>=2.5.0->recbole) (0.41.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->ray) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->ray) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->ray) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->ray) (2023.11.17)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\nRequirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema->ray) (23.1.0)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema->ray) (2023.7.1)\nRequirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema->ray) (0.30.2)\nRequirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema->ray) (0.9.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->ray) (3.0.9)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.5.0->recbole) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.5.0->recbole) (0.2.7)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.5.0->recbole) (4.9)\nRequirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.5.0->recbole) (1.16.0)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.5.0->recbole) (1.3.1)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.5.0->recbole) (0.4.8)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.5.0->recbole) (3.2.2)\nDownloading recbole-1.2.0-py3-none-any.whl (2.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\nInstalling collected packages: colorlog, kmeans_pytorch, colorama, thop, recbole\n  Attempting uninstall: colorlog\n    Found existing installation: colorlog 6.8.0\n    Uninstalling colorlog-6.8.0:\n      Successfully uninstalled colorlog-6.8.0\n  Attempting uninstall: colorama\n    Found existing installation: colorama 0.4.6\n    Uninstalling colorama-0.4.6:\n      Successfully uninstalled colorama-0.4.6\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbayesian-optimization 1.4.3 requires colorama>=0.4.6, but you have colorama 0.4.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed colorama-0.4.4 colorlog-4.7.2 kmeans_pytorch-0.3 recbole-1.2.0 thop-0.1.1.post2209072238\n","output_type":"stream"}]},{"cell_type":"code","source":"import polars as pl\nimport numpy as np\nimport torch\nimport datetime\nimport os\nimport gc\nfrom tqdm.auto import tqdm\n\nimport logging\nfrom logging import getLogger\n\nfrom recbole.config import Config\nfrom recbole.data import create_dataset, data_preparation\nfrom recbole.quick_start import run_recbole\nfrom recbole.quick_start.quick_start import load_data_and_model\nfrom recbole.model.sequential_recommender import SASRecF\nfrom recbole.trainer import Trainer\nfrom recbole.utils.utils import get_trainer\nfrom recbole.utils import init_seed, init_logger\nfrom recbole.utils.case_study import full_sort_topk\n\ndef conv_date(source_date):\n    return datetime.datetime.timestamp(source_date)\n\n\nRANDOM_STATE = 42\nN_PREDICTIONS = 100\nDEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\nDATASET_NAME = \"hh_recsys\"","metadata":{"ExecuteTime":{"end_time":"2024-02-04T19:08:52.013976400Z","start_time":"2024-02-04T19:08:48.895299500Z"},"execution":{"iopub.status.busy":"2024-02-22T12:12:16.137825Z","iopub.execute_input":"2024-02-22T12:12:16.138297Z","iopub.status.idle":"2024-02-22T12:12:37.644696Z","shell.execute_reply.started":"2024-02-22T12:12:16.138258Z","shell.execute_reply":"2024-02-22T12:12:37.643312Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2024-02-22 12:12:36,474\tINFO util.py:129 -- Outdated packages:\n  ipywidgets==7.7.1 found, needs ipywidgets>=8\nRun `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n2024-02-22 12:12:36,980\tINFO util.py:129 -- Outdated packages:\n  ipywidgets==7.7.1 found, needs ipywidgets>=8\nRun `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n","output_type":"stream"}]},{"cell_type":"code","source":"train_path = '/kaggle/input/boosters-hh-recsys/hh_recsys_train_hh.pq'\ntrain = pl.read_parquet(train_path, low_memory=True)\n\nvacancies_path = '/kaggle/input/boosters-hh-recsys/hh_recsys_vacancies.pq'\nvacancies = pl.read_parquet(vacancies_path, low_memory=True)\n\nvacancies = vacancies.with_columns(pl.col(\"compensation.from\").fill_null(strategy=\"min\"))\nvacancies = vacancies.with_columns(pl.when(pl.col(\"compensation.to\").is_null()).\n                                   then(pl.col(\"compensation.from\")).\n                                   otherwise(pl.col(\"compensation.to\")).\n                                   alias(\"compensation.to\"))\nvacancies = vacancies.with_columns(pl.col(\"compensation.currencyCode\").fill_null(\"RUR\"))\n\nvacancies = vacancies.with_columns(pl.col(\"description\").\n                                   str.replace_all(\"<.*?>\", \"\").  # убираем html-тэги\n                                   str.replace_all(\"&[A-Za-z0-9#]+;\", \"\").   # убираем entity вроде  &quot;\n                                   str.replace_all(\"[[:punct:]]\", \"\").   # убираем знаки препинания\n                                   str.to_lowercase())                       # к нижнему регистру\n\n# ключевые навыки записываем в строку через пробел и в нижнем регистре\nvacancies = vacancies.with_columns(pl.col(\"keySkills.keySkill\").list.join(' ').str.to_lowercase())\nvacancies = vacancies.with_columns(pl.col(\"keySkills.keySkill\").fill_null(\"NONE\"))\n\npairs = train.select(['user_id', 'vacancy_id', 'action_type', 'action_dt']).explode(['vacancy_id', 'action_type', 'action_dt'])","metadata":{"execution":{"iopub.status.busy":"2024-02-22T12:12:37.646564Z","iopub.execute_input":"2024-02-22T12:12:37.647535Z","iopub.status.idle":"2024-02-22T12:17:51.205307Z","shell.execute_reply.started":"2024-02-22T12:12:37.647496Z","shell.execute_reply":"2024-02-22T12:17:51.203347Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# # Преобразуем зарплаты в соответствии с курсом ЦБ (на 09.01.2023)\n# currency_rates = {\"UZS\": 0.007269,\n#                   \"KGS\": 1.01,\n#                   \"USD\": 89.69,\n#                   \"GEL\": 33.3,\n#                   \"BYR\": 28.23,\n#                   \"AZN\": 52.76,\n#                   \"KZT\": 0.197708,\n#                   \"UAH\": 2.36,\n#                   \"RUR\": 1.0,\n#                   \"EUR\": 99.19}\n\n# vacancies = vacancies.rename({\"compensation.currencyCode\": \"currencyRate\", \n#                               \"compensation.from\": \"compensation_from\", \n#                               \"compensation.to\": \"compensation_to\"})\n\n# vacancies = vacancies.with_columns(\n#     currencyRate=pl.col(\"currencyRate\").replace(currency_rates, default=0.0))  # для версии 0.20\n# # vacancies = vacancies.with_columns(\n# #     currencyRate=pl.col(\"currencyRate\").map_dict(currency_rates, default=0.0))  # для версии 0.19\n\n# vacancies = vacancies.with_columns(\n#     compensation_from = pl.col('compensation_from') * pl.col('currencyRate'))\n# vacancies = vacancies.with_columns(\n#     compensation_to = pl.col('compensation_to') * pl.col('currencyRate'))\n\n# # Переведем зарплату в символьный вид для SASRecF \n# vacancies = vacancies.with_columns(\n#     salary_from=(pl.col(\"compensation_from\").log10()*10).floor().cast(pl.Int64).cast(pl.Utf8)\n# ).with_columns(\n#     salary_to=(pl.col(\"compensation_to\").log10()*10).floor().cast(pl.Int64).cast(pl.Utf8))","metadata":{"execution":{"iopub.status.busy":"2024-02-21T11:27:34.581445Z","iopub.execute_input":"2024-02-21T11:27:34.581786Z","iopub.status.idle":"2024-02-21T11:27:34.905424Z","shell.execute_reply.started":"2024-02-21T11:27:34.581755Z","shell.execute_reply":"2024-02-21T11:27:34.903938Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"gc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-02-22T12:17:51.208862Z","iopub.execute_input":"2024-02-22T12:17:51.209337Z","iopub.status.idle":"2024-02-22T12:17:51.683176Z","shell.execute_reply.started":"2024-02-22T12:17:51.209299Z","shell.execute_reply":"2024-02-22T12:17:51.681935Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"10"},"metadata":{}}]},{"cell_type":"markdown","source":"---\n# SASRec\nhttps://www.recbole.io/docs/user_guide/model/sequential/sasrecf.html","metadata":{}},{"cell_type":"code","source":"if not os.path.exists(DATASET_NAME):\n    os.mkdir(DATASET_NAME)\n\n# для версии 0.20\npairs.with_columns(\n    action_dt=pl.col(\"action_dt\").map_elements(conv_date)\n).rename({\"user_id\": \"user_id:token\", \n          \"vacancy_id\": \"vacancy_id:token\", \n          \"action_type\": \"action_type:float\", \n          \"action_dt\": \"timestamp:float\"}\n        ).write_csv(\"./\" + DATASET_NAME + \"/hh_recsys.inter\", include_header=True, separator=\"\\t\")\n\nvacancies.with_columns(pl.col(\"keySkills.keySkill\").cast(pl.List(pl.Utf8)).list.join(\", \")\n).rename({\"vacancy_id\": \"vacancy_id:token\", \n        \"name\": \"name:token_seq\", \n        \"company.id\": \"company_id:token\",\n        \"description\": \"description:token_seq\",\n        \"keySkills.keySkill\": \"keySkills:token_seq\", \n        \"compensation.from\": \"compensation_from:float\",\n        \"compensation.to\": \"compensation_to:float\", \n        \"compensation.currencyCode\": \"compensation.currencyCode:token\",\n        \"area.id\": \"area_id:token\", \n        \"area.regionId\": \"area_regionId:token\",\n        \"employment\": \"employment:token\", \n        \"workSchedule\": \"workSchedule:token\", \n        \"workExperience\": \"workExperience:token\"}\n    ).write_csv(\"./\" + DATASET_NAME + \"/hh_recsys.item\", include_header=True, separator=\"\\t\")","metadata":{"execution":{"iopub.status.busy":"2024-02-22T11:44:48.232841Z","iopub.execute_input":"2024-02-22T11:44:48.233693Z","iopub.status.idle":"2024-02-22T11:46:21.221783Z","shell.execute_reply.started":"2024-02-22T11:44:48.233657Z","shell.execute_reply":"2024-02-22T11:46:21.220745Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"gc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-02-22T11:46:21.223999Z","iopub.execute_input":"2024-02-22T11:46:21.224769Z","iopub.status.idle":"2024-02-22T11:46:21.489707Z","shell.execute_reply.started":"2024-02-22T11:46:21.224732Z","shell.execute_reply":"2024-02-22T11:46:21.488750Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"code","source":"config_dict = {\n    \"data_path\": \"/kaggle/working\",\n    \"USER_ID_FIELD\": \"user_id\",\n    \"ITEM_ID_FIELD\": \"vacancy_id\",\n    \"RATING_FIELD\": \"action_type\",\n    \"TIME_FIELD\": \"timestamp\",\n    \"user_inter_num_interval\": \"[1, inf)\",\n    \"item_inter_num_interval\": \"[25, inf)\",\n    \"load_col\": {\n        \"inter\": ['user_id', 'vacancy_id', 'action_type', 'timestamp'],\n        \"item\": ['vacancy_id', 'name', 'company_id', 'keySkills', \n                 'area_id', 'area_regionId', 'employment', 'workSchedule', \n                 'workExperience']\n    }, \n    \"selected_features\": ['name', \n                          'company_id', \n                          'keySkills', \n                          'area_id', \n                          'area_regionId', \n                          'employment', \n                          'workSchedule', \n                          'workExperience'\n                         ],\n    'train_batch_size': 1024,\n    'eval_batch_size': 1024,\n    'hidden_size': 64,  \n    'inner_size': 256,  \n    \"neg_sampling\": None,\n    'train_neg_sample_args': None,\n    \"eval_args\": {\n        \"split\": {\"RS\": [0.95, 0.03, 0.02]},\n        \"group_by\": \"user\",\n        \"order\": \"TO\",\n        \"mode\": \"full\"\n    },\n    \"metrics\":  ['Recall', 'MRR'], \n    \"topk\": 100,\n    \"epochs\": 2,\n    \"stopping_step\": 2, \n    \"show_progress\": True,\n    \"valid_metric\": 'MRR@100',\n    \"learning_rate\": 0.003,\n}","metadata":{"execution":{"iopub.status.busy":"2024-02-22T11:46:21.490796Z","iopub.execute_input":"2024-02-22T11:46:21.491075Z","iopub.status.idle":"2024-02-22T11:46:22.259551Z","shell.execute_reply.started":"2024-02-22T11:46:21.491051Z","shell.execute_reply":"2024-02-22T11:46:22.258304Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"run_recbole(model='SASRecF', dataset=DATASET_NAME, config_dict=config_dict)","metadata":{"execution":{"iopub.status.busy":"2024-02-22T11:46:22.260738Z","iopub.execute_input":"2024-02-22T11:46:22.261037Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/recbole/data/dataset/dataset.py:1217: FutureWarning: using <built-in function len> in Series.agg cannot aggregate and has been deprecated. Use Series.transform to keep behavior unchanged.\n  split_point = np.cumsum(feat[field].agg(len))[:-1]\n","output_type":"stream"}]},{"cell_type":"code","source":"# parameter_dict = {\n#     'data_path': './',\n#     'USER_ID_FIELD': 'user_id',\n#     'ITEM_ID_FIELD': 'vacancy_id',\n#     'RATING_FIELD': 'action_type',\n#     'TIME_FIELD': 'timestamp', \n#     'user_inter_num_interval': \"[10,inf)\",\n#     'item_inter_num_interval': \"[15,inf)\",\n# #     'seq_len': {'vacancy_id': 10},\n#     'MAX_ITEM_LIST_LENGTH': 10,    \n#     'load_col': {'inter': ['user_id', 'vacancy_id', 'action_type', 'timestamp'],\n#                  'item': ['vacancy_id', 'name', 'company_id', 'keySkills', \n#                           'salary_from', 'salary_to', 'area_id', 'area_regionId', \n#                           'employment', 'workSchedule', 'workExperience']},\n#     'selected_features': ['name', 'company_id', 'keySkills', 'salary_from', \n#                           'salary_to', 'area_id', 'area_regionId', 'employment', \n#                           'workSchedule', 'workExperience'],\n#     'neg_sampling': None,\n#     'train_neg_sample_args': None,\n#     'train_batch_size': 1024,\n#     'eval_batch_size': 1024,\n#     'epochs': 25,\n#     'metrics': ['Recall', 'MRR'],\n#     'loss_type': 'CE',\n#     'topk': 100,\n#     'valid_metric': 'MRR@100',\n#     \"stopping_step\": 2,\n# #     'hidden_size': 64,\n# #     'inner_size': 256,\n#     'hidden_dropout_prob': 0.3,\n#     'attn_dropout_prob': 0.3,\n#     'eval_args': {'split': {'RS': [0.95, 0.03, 0.02]},\n#                   'group_by': 'user',\n#                   'order': 'TO',\n#                   'mode': 'full'},\n#     'seed': 42,\n#     'reproducibility': True,\n#     \"device\": DEVICE,\n# }","metadata":{"execution":{"iopub.status.busy":"2024-02-20T08:03:56.665726Z","iopub.execute_input":"2024-02-20T08:03:56.666036Z","iopub.status.idle":"2024-02-20T08:04:09.497665Z","shell.execute_reply.started":"2024-02-20T08:03:56.666010Z","shell.execute_reply":"2024-02-20T08:04:09.496301Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# parameter_dict = {\n#     'data_path': './',\n#     'USER_ID_FIELD': 'user_id',\n#     'ITEM_ID_FIELD': 'vacancy_id',\n#     'RATING_FIELD': 'action_type',\n#     'TIME_FIELD': 'timestamp', \n#     'user_inter_num_interval': \"[10,inf)\",\n#     'item_inter_num_interval': \"[15,inf)\",\n#     'seq_len': {'vacancy_id': 10},\n#     'MAX_ITEM_LIST_LENGTH': 10,    \n#     'load_col': {'inter': ['user_id', 'vacancy_id', 'action_type', 'timestamp'],\n#                  'item': ['vacancy_id', 'name', 'company_id', 'keySkills', \n#                           'salary_from', 'salary_to', 'area_id', 'area_regionId', \n#                           'employment', 'workSchedule', 'workExperience']},\n#     'selected_features': ['name', 'company_id', 'keySkills', 'salary_from', \n#                           'salary_to', 'area_id', 'area_regionId', 'employment', \n#                           'workSchedule', 'workExperience'],\n#     'neg_sampling': None,\n#     'train_neg_sample_args': None,\n#     'train_batch_size': 1024,\n#     'eval_batch_size': 1024,\n#     'epochs': 20,\n#     'metrics': ['Recall', 'MRR'],\n#     'loss_type': 'CE',\n#     'topk': 100,\n#     'valid_metric': 'MRR@100',\n#     \"stopping_step\": 2,\n#     'hidden_size': 64,\n#     'inner_size': 256,\n#     'hidden_dropout_prob': 0.3,\n#     'attn_dropout_prob': 0.3,\n#     'eval_args': {'split': {'RS': [0.95, 0.03, 0.02]},\n#                   'group_by': 'user',\n#                   'order': 'TO',\n#                   'mode': 'full'},\n#     'seed': 42,\n#     'reproducibility': True,\n#     \"device\": DEVICE,\n# }\n\n# Trainable parameters: 28041408\n# epoch 0 training [time: 2182.38s, train loss: 105236.6074]\n# epoch 0 evaluating [time: 61.79s, valid_score: 0.118000]\n# valid result: \n# recall@100 : 0.4858    mrr@100 : 0.118\n# Saving current: saved/SASRecF-Feb-19-2024_15-47-30.pth\n# epoch 1 training [time: 2185.21s, train loss: 91502.9345]\n# epoch 1 evaluating [time: 64.06s, valid_score: 0.133400]\n# valid result: \n# recall@100 : 0.5184    mrr@100 : 0.1334\n# Saving current: saved/SASRecF-Feb-19-2024_15-47-30.pth\n# epoch 2 training [time: 2194.06s, train loss: 88985.4760]\n# epoch 2 evaluating [time: 64.37s, valid_score: 0.141400]\n# valid result: \n# recall@100 : 0.5325    mrr@100 : 0.1414\n# Saving current: saved/SASRecF-Feb-19-2024_15-47-30.pth\n# epoch 3 training [time: 2197.01s, train loss: 87588.3414]\n# epoch 3 evaluating [time: 64.04s, valid_score: 0.143900]\n# valid result: \n# recall@100 : 0.5398    mrr@100 : 0.1439\n# Saving current: saved/SASRecF-Feb-19-2024_15-47-30.pth\n# epoch 4 training [time: 2197.31s, train loss: 86684.4105]\n# epoch 4 evaluating [time: 64.08s, valid_score: 0.146500]\n# valid result: \n# recall@100 : 0.544    mrr@100 : 0.1465\n# Saving current: saved/SASRecF-Feb-19-2024_15-47-30.pth\n# epoch 5 training [time: 2193.55s, train loss: 86042.4307]\n# epoch 5 evaluating [time: 64.01s, valid_score: 0.148200]\n# valid result: \n# recall@100 : 0.5468    mrr@100 : 0.1482\n# Saving current: saved/SASRecF-Feb-19-2024_15-47-30.pth\n# epoch 6 training [time: 2193.16s, train loss: 85564.8586]\n# epoch 6 evaluating [time: 64.82s, valid_score: 0.149500]\n# valid result: \n# recall@100 : 0.5483    mrr@100 : 0.1495\n# Saving current: saved/SASRecF-Feb-19-2024_15-47-30.pth\n# epoch 7 training [time: 2183.19s, train loss: 85195.1310]\n# epoch 7 evaluating [time: 63.33s, valid_score: 0.149800]\n# valid result: \n# recall@100 : 0.5509    mrr@100 : 0.1498\n# Saving current: saved/SASRecF-Feb-19-2024_15-47-30.pth","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# config = Config(model='SASRecF', dataset=DATASET_NAME, config_dict=parameter_dict)\n\n# init_seed(config['seed'], config['reproducibility'])\n\n# # инициализируем логгеры для вывода информации\n# logger = getLogger()\n# logger.setLevel(logging.INFO)\n\n# c_handler = logging.StreamHandler()\n# c_handler.setLevel(logging.INFO)\n\n# logger.addHandler(c_handler)\n# logger.info(config)\n\n# # Создаём объекты тренировочной выборки и валидацонной\n# dataset = create_dataset(config)\n# logger.info(dataset)\n# train_data, valid_data, test_data = data_preparation(config, dataset)\n\n# # Инициализируем модель и обучаем\n# model = SASRecF(config, train_data.dataset).to(config['device'])\n# logger.info(model)\n\n# # инициализируем \"тренера\" модели\n# trainer = Trainer(config, model)\n\n# # сохраняем лучшие результаты\n# best_valid_score, best_valid_result = trainer.fit(train_data, valid_data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# trainer.evaluate(test_data)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# del dataset\n# del train_data\n# del valid_data\n# del test_data\n\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-02-20T19:01:46.788562Z","iopub.execute_input":"2024-02-20T19:01:46.790024Z","iopub.status.idle":"2024-02-20T19:01:47.148778Z","shell.execute_reply.started":"2024-02-20T19:01:46.789985Z","shell.execute_reply":"2024-02-20T19:01:47.147750Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"962"},"metadata":{}}]},{"cell_type":"code","source":"!pip install gdown","metadata":{"execution":{"iopub.status.busy":"2024-02-21T20:56:33.540990Z","iopub.execute_input":"2024-02-21T20:56:33.541902Z","iopub.status.idle":"2024-02-21T20:56:45.259663Z","shell.execute_reply.started":"2024-02-21T20:56:33.541861Z","shell.execute_reply":"2024-02-21T20:56:45.258675Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Collecting gdown\n  Obtaining dependency information for gdown from https://files.pythonhosted.org/packages/cb/56/f4845ed78723a4eb8eb22bcfcb46e1157a462c78c0a5ed318c68c98f9a79/gdown-5.1.0-py3-none-any.whl.metadata\n  Downloading gdown-5.1.0-py3-none-any.whl.metadata (5.7 kB)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from gdown) (4.12.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from gdown) (3.12.2)\nRequirement already satisfied: requests[socks] in /opt/conda/lib/python3.10/site-packages (from gdown) (2.31.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from gdown) (4.66.1)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->gdown) (2.3.2.post1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (2023.11.17)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.7.1)\nDownloading gdown-5.1.0-py3-none-any.whl (17 kB)\nInstalling collected packages: gdown\nSuccessfully installed gdown-5.1.0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"saved/SASRecF-Feb-20-2024_14-30-24.pth\n\nhttps://drive.google.com/file/d/1JCvq-LLztH8CCFWsU-kH2LM58Yb-BBNZ/view?usp=sharing","metadata":{}},{"cell_type":"code","source":"!gdown 1JCvq-LLztH8CCFWsU-kH2LM58Yb-BBNZ\n!unzip -q saved.zip","metadata":{"execution":{"iopub.status.busy":"2024-02-21T20:56:58.638350Z","iopub.execute_input":"2024-02-21T20:56:58.639283Z","iopub.status.idle":"2024-02-21T20:57:39.824927Z","shell.execute_reply.started":"2024-02-21T20:56:58.639248Z","shell.execute_reply":"2024-02-21T20:57:39.823695Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Downloading...\nFrom (original): https://drive.google.com/uc?id=1JCvq-LLztH8CCFWsU-kH2LM58Yb-BBNZ\nFrom (redirected): https://drive.google.com/uc?id=1JCvq-LLztH8CCFWsU-kH2LM58Yb-BBNZ&confirm=t&uuid=4a17c6d8-e4c6-4f85-ac59-3b49193a2c68\nTo: /kaggle/working/saved.zip\n100%|█████████████████████████████████████████| 294M/294M [00:01<00:00, 233MB/s]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"hh_recsys\n\nhttps://drive.google.com/file/d/1hGs8jBChC9BkSOZlBzzU1WlYxbKpAUZ-/view?usp=sharing","metadata":{}},{"cell_type":"code","source":"!gdown 1hGs8jBChC9BkSOZlBzzU1WlYxbKpAUZ-\n!unzip -q hh_recsys.zip","metadata":{"execution":{"iopub.status.busy":"2024-02-21T20:59:09.951877Z","iopub.execute_input":"2024-02-21T20:59:09.952471Z","iopub.status.idle":"2024-02-21T21:00:21.021776Z","shell.execute_reply.started":"2024-02-21T20:59:09.952438Z","shell.execute_reply":"2024-02-21T21:00:21.019812Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Downloading...\nFrom (original): https://drive.google.com/uc?id=1hGs8jBChC9BkSOZlBzzU1WlYxbKpAUZ-\nFrom (redirected): https://drive.google.com/uc?id=1hGs8jBChC9BkSOZlBzzU1WlYxbKpAUZ-&confirm=t&uuid=6026eb42-fb28-4703-8d9b-5196eb2ce370\nTo: /kaggle/working/hh_recsys.zip\n100%|███████████████████████████████████████| 1.79G/1.79G [00:10<00:00, 167MB/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"gc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-02-21T21:08:05.105164Z","iopub.execute_input":"2024-02-21T21:08:05.105522Z","iopub.status.idle":"2024-02-21T21:08:05.369243Z","shell.execute_reply.started":"2024-02-21T21:08:05.105493Z","shell.execute_reply":"2024-02-21T21:08:05.368377Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"499"},"metadata":{}}]},{"cell_type":"code","source":"from recbole.utils import init_seed, init_logger, get_model\n\nmodel_file_path = '/kaggle/working/saved/SASRecF-Feb-20-2024_14-30-24.pth'\ncheckpoint = torch.load(model_file_path)\n# config = checkpoint[\"config\"]\nmodel = get_model(config[\"model\"])(config, train_data.dataset).to(config['device'])\nmodel.load_state_dict(checkpoint[\"state_dict\"])\nmodel.load_other_parameter(checkpoint.get(\"other_parameter\"))","metadata":{"execution":{"iopub.status.busy":"2024-02-21T21:07:24.818741Z","iopub.execute_input":"2024-02-21T21:07:24.819382Z","iopub.status.idle":"2024-02-21T21:07:59.708305Z","shell.execute_reply.started":"2024-02-21T21:07:24.819346Z","shell.execute_reply":"2024-02-21T21:07:59.707088Z"},"trusted":true},"execution_count":13,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[13], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(model_file_path)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# config = checkpoint[\"config\"]\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m model \u001b[38;5;241m=\u001b[39m get_model(config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m])(config, \u001b[43mtrain_data\u001b[49m\u001b[38;5;241m.\u001b[39mdataset)\u001b[38;5;241m.\u001b[39mto(config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      7\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(checkpoint[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstate_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      8\u001b[0m model\u001b[38;5;241m.\u001b[39mload_other_parameter(checkpoint\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mother_parameter\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n","\u001b[0;31mNameError\u001b[0m: name 'train_data' is not defined"],"ename":"NameError","evalue":"name 'train_data' is not defined","output_type":"error"}]},{"cell_type":"code","source":"train_data, valid_data, test_data = data_preparation(config, dataset)\nmodel = SASRecF(config, train_data.dataset).to(config['device'])","metadata":{"execution":{"iopub.status.busy":"2024-02-21T21:08:27.695005Z","iopub.execute_input":"2024-02-21T21:08:27.695936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"config = Config(model='SASRecF', dataset=DATASET_NAME, config_dict=config_dict)\ndataset = create_dataset(config)","metadata":{"execution":{"iopub.status.busy":"2024-02-21T21:01:07.282164Z","iopub.execute_input":"2024-02-21T21:01:07.283037Z","iopub.status.idle":"2024-02-21T21:06:32.533661Z","shell.execute_reply.started":"2024-02-21T21:01:07.283004Z","shell.execute_reply":"2024-02-21T21:06:32.532697Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/recbole/data/dataset/dataset.py:1217: FutureWarning: using <built-in function len> in Series.agg cannot aggregate and has been deprecated. Use Series.transform to keep behavior unchanged.\n  split_point = np.cumsum(feat[field].agg(len))[:-1]\n","output_type":"stream"}]},{"cell_type":"code","source":"model_path = '/kaggle/working/saved/SASRecF-Feb-20-2024_14-30-24.pth'\nmodel.load_state_dict(torch.load(model_path))","metadata":{"execution":{"iopub.status.busy":"2024-02-21T20:58:22.456164Z","iopub.execute_input":"2024-02-21T20:58:22.456489Z","iopub.status.idle":"2024-02-21T20:58:22.501113Z","shell.execute_reply.started":"2024-02-21T20:58:22.456465Z","shell.execute_reply":"2024-02-21T20:58:22.499943Z"},"trusted":true},"execution_count":8,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[8], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrecbole\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m init_seed, init_logger\n\u001b[1;32m      6\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/kaggle/working/saved/SASRecF-Feb-20-2024_14-30-24.pth\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 7\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(model_path))\n","\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"],"ename":"NameError","evalue":"name 'model' is not defined","output_type":"error"}]},{"cell_type":"markdown","source":"---\n# ALS","metadata":{}},{"cell_type":"code","source":"!pip install implicit","metadata":{"execution":{"iopub.status.busy":"2024-02-21T19:26:26.710816Z","iopub.execute_input":"2024-02-21T19:26:26.711572Z","iopub.status.idle":"2024-02-21T19:26:39.275514Z","shell.execute_reply.started":"2024-02-21T19:26:26.711538Z","shell.execute_reply":"2024-02-21T19:26:39.274395Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Collecting implicit\n  Obtaining dependency information for implicit from https://files.pythonhosted.org/packages/cd/cc/deac70cae8cc32c9885d0cd73bc66e1b3cbea36ae7080b8c83995eaf5322/implicit-0.7.2-cp310-cp310-manylinux2014_x86_64.whl.metadata\n  Downloading implicit-0.7.2-cp310-cp310-manylinux2014_x86_64.whl.metadata (6.1 kB)\nRequirement already satisfied: numpy>=1.17.0 in /opt/conda/lib/python3.10/site-packages (from implicit) (1.24.3)\nRequirement already satisfied: scipy>=0.16 in /opt/conda/lib/python3.10/site-packages (from implicit) (1.11.4)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from implicit) (4.66.1)\nRequirement already satisfied: threadpoolctl in /opt/conda/lib/python3.10/site-packages (from implicit) (3.2.0)\nDownloading implicit-0.7.2-cp310-cp310-manylinux2014_x86_64.whl (8.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m68.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: implicit\nSuccessfully installed implicit-0.7.2\n","output_type":"stream"}]},{"cell_type":"code","source":"from scipy.sparse import csr_matrix\nimport implicit","metadata":{"execution":{"iopub.status.busy":"2024-02-21T19:26:42.608038Z","iopub.execute_input":"2024-02-21T19:26:42.608853Z","iopub.status.idle":"2024-02-21T19:26:42.628383Z","shell.execute_reply.started":"2024-02-21T19:26:42.608817Z","shell.execute_reply":"2024-02-21T19:26:42.627655Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"unique_users = train['user_id'].unique().to_list()\nunique_vacancies = train['vacancy_id'].explode().unique().to_list()\n\nuser2idx = {user_id: idx for idx, user_id in enumerate(unique_users)}\nvac2idx = {vac_id: idx for idx, vac_id in enumerate(unique_vacancies)}\nidx2vac = {idx: vac_id for vac_id, idx in vac2idx.items()}\n\naction_weights = {\n    1: 4.0,\n    2: 1.0,\n    3: 2.0\n}\n\n# для версии 0.20\nusers_list = pairs['user_id'].replace(user2idx, default=None).to_numpy()\nvacancies_list = pairs['vacancy_id'].replace(vac2idx, default=None).to_numpy()\npreferences = pairs['action_type'].replace(action_weights, default=None).to_numpy()","metadata":{"execution":{"iopub.status.busy":"2024-02-21T19:26:55.229071Z","iopub.execute_input":"2024-02-21T19:26:55.230486Z","iopub.status.idle":"2024-02-21T19:27:05.301144Z","shell.execute_reply.started":"2024-02-21T19:26:55.230453Z","shell.execute_reply":"2024-02-21T19:27:05.300331Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"uv_mat = csr_matrix((preferences, (users_list, vacancies_list)))\n\nals_model = implicit.als.AlternatingLeastSquares(\n    factors=200,   # 150\n    random_state=RANDOM_STATE,\n    iterations=100,\n    alpha=3.0,\n    calculate_training_loss=True,\n    regularization=0.001,\n    num_threads=8\n)\nals_model.fit(uv_mat)","metadata":{"execution":{"iopub.status.busy":"2024-02-21T19:27:15.135659Z","iopub.execute_input":"2024-02-21T19:27:15.136018Z","iopub.status.idle":"2024-02-21T19:32:50.303811Z","shell.execute_reply.started":"2024-02-21T19:27:15.135990Z","shell.execute_reply":"2024-02-21T19:32:50.302827Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/100 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"977b24a0e1aa4590934cf0a5417f3097"}},"metadata":{}}]},{"cell_type":"code","source":"import pickle\nwith open('ALS-200-fulldata.pkl', 'wb') as f:\n    pickle.dump(als_model, f)","metadata":{"execution":{"iopub.status.busy":"2024-02-21T19:33:53.771123Z","iopub.execute_input":"2024-02-21T19:33:53.771518Z","iopub.status.idle":"2024-02-21T19:34:05.875398Z","shell.execute_reply.started":"2024-02-21T19:33:53.771486Z","shell.execute_reply":"2024-02-21T19:34:05.874343Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"del train\ndel vacancies\ndel pairs","metadata":{"execution":{"iopub.status.busy":"2024-02-21T19:39:40.803536Z","iopub.execute_input":"2024-02-21T19:39:40.804205Z","iopub.status.idle":"2024-02-21T19:39:41.296464Z","shell.execute_reply.started":"2024-02-21T19:39:40.804173Z","shell.execute_reply":"2024-02-21T19:39:41.295644Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"test = pl.read_parquet(\"/kaggle/input/boosters-hh-recsys/hh_recsys_test_hh.pq\", low_memory=True)\ntest_users = test['user_id'].to_list()\ntest_vacancies = test.select(pl.col('vacancy_id').list.unique(maintain_order=True))['vacancy_id'].to_list()","metadata":{"execution":{"iopub.status.busy":"2024-02-21T19:53:37.530480Z","iopub.execute_input":"2024-02-21T19:53:37.531380Z","iopub.status.idle":"2024-02-21T19:53:38.065794Z","shell.execute_reply.started":"2024-02-21T19:53:37.531337Z","shell.execute_reply":"2024-02-21T19:53:38.064747Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"# Предсказание ALS\npredictions = []\n\nfor user, vacs in tqdm(zip(test_users, test_vacancies), total=len(test_users)):\n    if user not in user2idx:\n        predictions.append(vacs)\n        continue\n    \n    cuser = user2idx[user]\n\n    recommendations = als_model.recommend(cuser, \n                                          uv_mat[cuser], \n                                          N=N_PREDICTIONS, \n                                          filter_already_liked_items=False)[0]\n    recommendations = [idx2vac[cv] for cv in recommendations]\n    predictions.append(recommendations)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = test.with_columns(pl.lit(pl.Series(predictions)).alias('predictions'))\ntest.select(['user_id', 'session_id', 'predictions']).write_parquet('als_submission.pq')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n# LightFM","metadata":{}},{"cell_type":"code","source":"!pip install lightfm","metadata":{"execution":{"iopub.status.busy":"2024-02-22T12:18:28.417686Z","iopub.execute_input":"2024-02-22T12:18:28.418173Z","iopub.status.idle":"2024-02-22T12:18:58.081894Z","shell.execute_reply.started":"2024-02-22T12:18:28.418139Z","shell.execute_reply":"2024-02-22T12:18:58.080654Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Collecting lightfm\n  Downloading lightfm-1.17.tar.gz (316 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.4/316.4 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from lightfm) (1.24.3)\nRequirement already satisfied: scipy>=0.17.0 in /opt/conda/lib/python3.10/site-packages (from lightfm) (1.11.4)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from lightfm) (2.31.0)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from lightfm) (1.2.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->lightfm) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->lightfm) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->lightfm) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->lightfm) (2023.11.17)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->lightfm) (1.3.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->lightfm) (3.2.0)\nBuilding wheels for collected packages: lightfm\n  Building wheel for lightfm (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for lightfm: filename=lightfm-1.17-cp310-cp310-linux_x86_64.whl size=464219 sha256=481e01c09004cfb299b3586311cbdd4f963eb4704b417e81b0006df386f10c4a\n  Stored in directory: /root/.cache/pip/wheels/4f/9b/7e/0b256f2168511d8fa4dae4fae0200fdbd729eb424a912ad636\nSuccessfully built lightfm\nInstalling collected packages: lightfm\nSuccessfully installed lightfm-1.17\n","output_type":"stream"}]},{"cell_type":"code","source":"from lightfm import LightFM\nfrom lightfm.data import Dataset\nfrom scipy.sparse import csr_matrix","metadata":{"execution":{"iopub.status.busy":"2024-02-22T12:19:06.899415Z","iopub.execute_input":"2024-02-22T12:19:06.899822Z","iopub.status.idle":"2024-02-22T12:19:06.906607Z","shell.execute_reply.started":"2024-02-22T12:19:06.899791Z","shell.execute_reply":"2024-02-22T12:19:06.905118Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"unique_users = train['user_id'].unique().to_list()\nunique_vacancies = train['vacancy_id'].explode().unique().to_list()\n\nuser2idx = {user_id: idx for idx, user_id in enumerate(unique_users)}\nvac2idx = {vac_id: idx for idx, vac_id in enumerate(unique_vacancies)}\nidx2vac = {idx: vac_id for vac_id, idx in vac2idx.items()}\n\naction_weights = {\n    1: 4.0,\n    2: 1.0,\n    3: 2.0\n}\n\n# для версии 0.20\nusers_list = pairs['user_id'].replace(user2idx, default=None).to_numpy()\nvacancies_list = pairs['vacancy_id'].replace(vac2idx, default=None).to_numpy()\npreferences = pairs['action_type'].replace(action_weights, default=None).to_numpy()\n\nuv_mat = csr_matrix((preferences, (users_list, vacancies_list)))","metadata":{"execution":{"iopub.status.busy":"2024-02-22T12:19:13.853870Z","iopub.execute_input":"2024-02-22T12:19:13.854335Z","iopub.status.idle":"2024-02-22T12:19:34.351097Z","shell.execute_reply.started":"2024-02-22T12:19:13.854304Z","shell.execute_reply":"2024-02-22T12:19:34.349750Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"lfm_params = {\n    'no_components': 64,\n    'learning_rate': 0.01,\n    'max_sampled': 5,\n    'loss': 'warp',\n    'random_state': 42\n    }\nlfm_model = LightFM(**lfm_params)\n\nnum_epochs = 50\nfor _ in tqdm(range(num_epochs)):\n    lfm_model.fit_partial(uv_mat)","metadata":{"execution":{"iopub.status.busy":"2024-02-22T12:19:44.482243Z","iopub.execute_input":"2024-02-22T12:19:44.482678Z"},"trusted":true},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"77b7d5a5477d475ab465693acdf6558f"}},"metadata":{}}]},{"cell_type":"code","source":"del train\ndel vacancies\ndel pairs","metadata":{"execution":{"iopub.status.busy":"2024-02-21T19:39:40.803536Z","iopub.execute_input":"2024-02-21T19:39:40.804205Z","iopub.status.idle":"2024-02-21T19:39:41.296464Z","shell.execute_reply.started":"2024-02-21T19:39:40.804173Z","shell.execute_reply":"2024-02-21T19:39:41.295644Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"test = pl.read_parquet(\"/kaggle/input/boosters-hh-recsys/hh_recsys_test_hh.pq\", low_memory=True)\ntest_users = test['user_id'].to_list()\ntest_vacancies = test.select(pl.col('vacancy_id').list.unique(maintain_order=True))['vacancy_id'].to_list()","metadata":{"execution":{"iopub.status.busy":"2024-02-21T19:53:37.530480Z","iopub.execute_input":"2024-02-21T19:53:37.531380Z","iopub.status.idle":"2024-02-21T19:53:38.065794Z","shell.execute_reply.started":"2024-02-21T19:53:37.531337Z","shell.execute_reply":"2024-02-21T19:53:38.064747Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"# Предсказание ALS\npredictions = []\n\nfor user, vacs in tqdm(zip(test_users, test_vacancies), total=len(test_users)):\n    if user not in user2idx:\n        predictions.append(vacs)\n        continue\n    \n    cuser = user2idx[user]\n\n    recommendations = als_model.recommend(cuser, \n                                          uv_mat[cuser], \n                                          N=N_PREDICTIONS, \n                                          filter_already_liked_items=False)[0]\n    recommendations = [idx2vac[cv] for cv in recommendations]\n    predictions.append(recommendations)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = test.with_columns(pl.lit(pl.Series(predictions)).alias('predictions'))\ntest.select(['user_id', 'session_id', 'predictions']).write_parquet('als_submission.pq')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n# ALS + SASRecF","metadata":{}},{"cell_type":"code","source":"def add_last_vacancy(old_interaction, last_vacancy_id, max_len=10):   # изначально max_len=50\n    new_seq_vacancies = old_interaction['vacancy_id_list'][-1]\n    if old_interaction['item_length'][-1].item() < max_len:\n        new_seq_vacancies[old_interaction['item_length'][-1].item()] = last_vacancy_id\n    else:\n        new_seq_vacancies = torch.roll(new_seq_vacancies, -1)\n        new_seq_vacancies[-1] = last_vacancy_id\n    return new_seq_vacancies.view(1, len(new_seq_vacancies))\n\n\ndef predict_for_all_item(external_user_id, dataset, model):\n    model.eval()\n    with torch.no_grad():\n        uid_series = dataset.token2id(dataset.uid_field, [external_user_id])\n        index = np.isin(dataset.inter_feat[dataset.uid_field].numpy(), uid_series)\n        input_interaction = dataset[np.nonzero(index)[0]]\n#         input_interaction = dataset[index]  # 9 секунд на полном датасете\n        test = {'vacancy_id_list': add_last_vacancy(\n            input_interaction, input_interaction['vacancy_id'][-1].item(), model.max_seq_length),\n                'item_length': torch.tensor(\n                    [input_interaction['item_length'][-1].item() + 1 \n                     if input_interaction['item_length'][-1].item() < model.max_seq_length else model.max_seq_length])\n        }\n        new_inter = Interaction(test)\n        new_inter = new_inter.to(config['device'])\n        new_scores = model.full_sort_predict(new_inter)\n        new_scores = new_scores.view(-1, test_data.dataset.item_num)\n        new_scores[:, 0] = -np.inf  # set scores of [pad] to -inf\n    return torch.topk(new_scores, N_PREDICTIONS)","metadata":{"execution":{"iopub.status.busy":"2024-02-21T19:53:45.851136Z","iopub.execute_input":"2024-02-21T19:53:45.851522Z","iopub.status.idle":"2024-02-21T19:53:45.865621Z","shell.execute_reply.started":"2024-02-21T19:53:45.851494Z","shell.execute_reply":"2024-02-21T19:53:45.864648Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"# predictions = []\n# num_not_found = 0\n# zero_topk = 0\n\n# dataset_uids = dataset.field2token_id[dataset.uid_field]\n\n# for user, vacs in tqdm(zip(test_users, test_vacancies), total=len(test_users)):\n# #    if user not in dataset.field2token_id[dataset.uid_field]:   # либо в тесте есть такой юзер, которого не было в трейне, либо в трейне он отсеялся по порогу (?)\n#     if user not in dataset_uids:   # либо в тесте есть такой юзер, которого не было в трейне, либо в трейне он отсеялся по порогу (?)\n#         predictions.append(vacs)\n#         num_not_found += 1\n#         continue\n\n# #    cuser = dataset.token2id(dataset.uid_field, user)   # получили id очередного юзера по его имени\n# #    _, topk_iid_list = full_sort_topk([cuser], model, test_data, k=N_PREDICTIONS, device='cpu')\n#     _, topk_iid_list = predict_for_all_item(user, dataset, model)\n#     if len(topk_iid_list) == 0:\n#         predictions.append(vacs)\n#         zero_topk += 1\n#         continue\n\n#     last_topk_iid_list = topk_iid_list[-1]\n#     recommendations = dataset.id2token(dataset.iid_field, last_topk_iid_list.cpu()).tolist()\n\n#     predictions.append(recommendations)\n\n# print(\"Not found: \", num_not_found)\n# print(\"Zero topk: \", zero_topk)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = []\nnum_not_found = 0\nnum_not_found_als = 0\nzero_topk = 0\n\ndataset_uids = dataset.field2token_id[dataset.uid_field]\n\nfor user, vacs in tqdm(zip(test_users, test_vacancies), total=len(test_users)):\n#    if user not in dataset.field2token_id[dataset.uid_field]:\n    if user not in dataset_uids:\n        if user not in user2idx:\n             predictions.append(vacs)\n             num_not_found_als += 1\n             continue\n        cuser = user2idx[user]\n        \n        recommendations = als_model.recommend(cuser, uv_mat[cuser], N=N_PREDICTIONS, filter_already_liked_items=False)[0]\n        recommendations = [idx2vac[cv] for cv in recommendations]\n        predictions.append(recommendations)\n\n        num_not_found += 1\n        continue\n\n#    cuser = dataset.token2id(dataset.uid_field, user)   # получили id очередного юзера по его имени\n#    _, topk_iid_list = full_sort_topk([cuser], model, test_data, k=N_PREDICTIONS, device='cpu')\n    _, topk_iid_list = predict_for_all_item(user, dataset, model)\n    if len(topk_iid_list) == 0:\n        if user not in user2idx:\n             predictions.append(vacs)\n             num_not_found_als += 1\n             continue\n        cuser = user2idx[user]\n        \n        recommendations = als_model.recommend(cuser, uv_mat[cuser], N=N_PREDICTIONS, filter_already_liked_items=False)[0]\n        recommendations = [idx2vac[cv] for cv in recommendations]\n        predictions.append(recommendations)\n\n        zero_topk += 1\n        continue\n\n    last_topk_iid_list = topk_iid_list[-1]\n    recommendations = dataset.id2token(dataset.iid_field, last_topk_iid_list.cpu()).tolist()\n\n    predictions.append(recommendations)\n\nprint(\"Not found: \", num_not_found)\nprint(\"Not found by ALS: \", num_not_found_als)\nprint(\"Zero topk: \", zero_topk)","metadata":{"execution":{"iopub.status.busy":"2024-02-21T19:53:56.808812Z","iopub.execute_input":"2024-02-21T19:53:56.809233Z","iopub.status.idle":"2024-02-21T19:53:56.952517Z","shell.execute_reply.started":"2024-02-21T19:53:56.809200Z","shell.execute_reply":"2024-02-21T19:53:56.951151Z"},"trusted":true},"execution_count":32,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/83189 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"086e1173b1fc48ce85f1c243683542e0"}},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[32], line 26\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m#    cuser = dataset.token2id(dataset.uid_field, user)   # получили id очередного юзера по его имени\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m#    _, topk_iid_list = full_sort_topk([cuser], model, test_data, k=N_PREDICTIONS, device='cpu')\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m     _, topk_iid_list \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_for_all_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(topk_iid_list) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     28\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m user \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m user2idx:\n","Cell \u001b[0;32mIn[31], line 12\u001b[0m, in \u001b[0;36mpredict_for_all_item\u001b[0;34m(external_user_id, dataset, model)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_for_all_item\u001b[39m(external_user_id, dataset, model):\n\u001b[0;32m---> 12\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m()\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     14\u001b[0m         uid_series \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mtoken2id(dataset\u001b[38;5;241m.\u001b[39muid_field, [external_user_id])\n","\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'eval'"],"ename":"AttributeError","evalue":"'dict' object has no attribute 'eval'","output_type":"error"}]},{"cell_type":"code","source":"test = test.with_columns(pl.lit(pl.Series(predictions)).alias('predictions'))\ntest.select(['user_id', 'session_id', 'predictions']).write_parquet('sasrecf_als_submission.pq')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = test.with_columns(pl.lit(pl.Series(predictions)).alias('predictions'))\ntest.select(['user_id', 'session_id', 'predictions']).write_parquet('als_submission.pq')","metadata":{"execution":{"iopub.status.busy":"2024-02-16T15:32:02.794909Z","iopub.execute_input":"2024-02-16T15:32:02.79532Z","iopub.status.idle":"2024-02-16T15:32:06.512962Z","shell.execute_reply.started":"2024-02-16T15:32:02.795288Z","shell.execute_reply":"2024-02-16T15:32:06.51214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = test.select(pl.col('vacancy_id').list.unique(maintain_order=True).list.tail(2))['vacancy_id'].to_list()\n\ntest = test.with_columns(pl.lit(pl.Series(predictions)).alias('predictions'))\ntest.select(['user_id', 'session_id', 'predictions']).write_parquet('submission.pq')","metadata":{"execution":{"iopub.status.busy":"2024-02-16T15:49:50.434973Z","iopub.execute_input":"2024-02-16T15:49:50.435887Z","iopub.status.idle":"2024-02-16T15:49:51.933613Z","shell.execute_reply.started":"2024-02-16T15:49:50.435855Z","shell.execute_reply":"2024-02-16T15:49:51.932831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test","metadata":{"execution":{"iopub.status.busy":"2024-02-16T15:50:02.832054Z","iopub.execute_input":"2024-02-16T15:50:02.832858Z","iopub.status.idle":"2024-02-16T15:50:02.853223Z","shell.execute_reply.started":"2024-02-16T15:50:02.832828Z","shell.execute_reply":"2024-02-16T15:50:02.852331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()\ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2024-02-21T19:59:22.806315Z","iopub.execute_input":"2024-02-21T19:59:22.806713Z","iopub.status.idle":"2024-02-21T19:59:23.163779Z","shell.execute_reply.started":"2024-02-21T19:59:22.806683Z","shell.execute_reply":"2024-02-21T19:59:23.162618Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"# Optuna","metadata":{}},{"cell_type":"code","source":"# !pip install optuna","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Импортируем необходимые библиотеки\n# import optuna\n# from recbole.quick_start import run_recbole\n# from recbole.config import Config\n# from recbole.utils import init_seed\n\n# # Задаем конфигурацию модели и данных\n# base_config_dict = {\n#     'data_path': './',\n#     'USER_ID_FIELD': 'user_id',\n#     'ITEM_ID_FIELD': 'vacancy_id',\n#     'RATING_FIELD': 'action_type',\n#     'TIME_FIELD': 'timestamp', \n#     'user_inter_num_interval': \"[10,inf)\",\n#     'item_inter_num_interval': \"[15,inf)\",\n# #     'seq_len': {'vacancy_id': 10},\n#     'MAX_ITEM_LIST_LENGTH': 10,    \n#     'load_col': {'inter': ['user_id', 'vacancy_id', 'action_type', 'timestamp'],\n#                  'item': ['vacancy_id', 'name', 'company_id', 'keySkills', \n#                           'salary_from', 'salary_to', 'area_id', 'area_regionId', \n#                           'employment', 'workSchedule', 'workExperience']},\n#     'selected_features': ['name', 'company_id', 'keySkills', 'salary_from', \n#                           'salary_to', 'area_id', 'area_regionId', 'employment', \n#                           'workSchedule', 'workExperience'],\n#     'neg_sampling': None,\n#     'train_neg_sample_args': None,\n#     'train_batch_size': 1024,\n#     'eval_batch_size': 1024,\n#     'epochs': 25,\n#     'metrics': ['MRR'],\n#     'loss_type': 'CE',\n#     'topk': 100,\n#     'valid_metric': 'MRR@100',\n#     \"stopping_step\": 2,\n# #     'hidden_size': 64,\n# #     'inner_size': 256,\n#     'hidden_dropout_prob': 0.3,\n#     'attn_dropout_prob': 0.3,\n#     'eval_args': {'split': {'RS': [0.95, 0.03, 0.02]},\n#                   'group_by': 'user',\n#                   'order': 'TO',\n#                   'mode': 'full'},\n#     'seed': 42,\n#     'reproducibility': True,\n#     \"device\": DEVICE,\n# }\n\n# # Определяем функцию для оптимизации гиперпараметров\n# def objective(trial):\n#     # Случайным образом выбираем значения гиперпараметров из заданных диапазонов\n#     learning_rate = trial.suggest_float(\"learning_rate\", 1e-4, 1e-2, log=True)\n#     # l2_reg = trial.suggest_float(\"l2_reg\", 1e-5, 1e-3, log=True)\n# #     hidden_size = trial.suggest_int(\"hidden_size\", 128, 256, step=64)\n#     num_layers = trial.suggest_int(\"num_layers\", 1, 4)\n#     dropout_prob = trial.suggest_float(\"dropout_prob\", 0.1, 0.5)\n#     MAX_ITEM_LIST_LENGTH = trial.suggest_int(\"MAX_ITEM_LIST_LENGTH\", 80, 160, step=20)\n\n#     parameter_overwrite = {\n# #         \"learning_rate\": learning_rate,\n# #         \"reg_weight\": l2_reg,\n#         \"hidden_size\": hidden_size,\n#         \"num_layers\": num_layers,\n#         \"dropout_prob\": dropout_prob,\n#         \"MAX_ITEM_LIST_LENGTH\": MAX_ITEM_LIST_LENGTH\n#     }\n\n#     # Combine base config with dynamic parameters\n#     combined_config = {**base_config_dict, **parameter_overwrite}\n\n#     # Инициализируем случайный сид для воспроизводимости\n#     init_seed(combined_config[\"seed\"], combined_config[\"reproducibility\"])\n\n#     # Specify the model and dataset\n#     model = 'GRU4Rec'\n#     dataset = 'recbole_data'  # Ensure this matches your dataset's name\n\n#     # Run the experiment\n#     result_dict = run_recbole(model=model, dataset=dataset, config_dict=combined_config)\n\n#     # Extract the best validation score\n#     best_valid_score = result_dict['best_valid_score']\n#     return best_valid_score\n\n# # Создаем объект студии optuna\n# study = optuna.create_study(direction=\"maximize\")\n\n# # Запускаем оптимизацию гиперпараметров с заданным количеством итераций\n# study.optimize(objective, n_trials=10)\n\n# # Выводим лучшие значения гиперпараметров и метрику\n# print(\"Best hyperparameters: \", study.best_params)\n# print(\"Best valid score: \", study.best_value)","metadata":{},"execution_count":null,"outputs":[]}]}